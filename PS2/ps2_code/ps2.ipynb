{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CS 4476 Problem Set 2: Local Feature Matching](https://faculty.cc.gatech.edu/~judy/cs4476-sp22/)\n",
    "\n",
    "This Jupyter notebook:  \n",
    "(1) Loads and resizes images  \n",
    "(2) Finds interest points in those images                 (you code this)  \n",
    "(3) Describes each interest point with a local feature    (you code this)  \n",
    "(4) Finds matching features                               (you code this)  \n",
    "(5) Visualizes the matches  \n",
    "(6) Evaluates the matches based on ground truth correspondences  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "from student_feature_matching import match_features, pca, accelerated_matching\n",
    "from student_sift import get_features\n",
    "from student_harris import get_interest_points\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "\n",
    "from ps2_unit_tests.harris_unit_test import (\n",
    "    test_get_gradients,\n",
    "    test_get_gradients2,\n",
    "    test_gaussian_kernel, \n",
    "    test_second_moment, \n",
    "    test_corner_response, \n",
    "    test_get_interest_points,\n",
    "    test_find_single_valid_corner,\n",
    "    verify\n",
    ")\n",
    "from ps2_unit_tests.sift_unit_test import (\n",
    "    test_get_magnitudes_and_orientations,\n",
    "    test_get_feat_vec,\n",
    "    test_get_features, \n",
    ")\n",
    "\n",
    "from ps2_unit_tests.feature_match_test import (\n",
    "    test_compute_dists,\n",
    "    test_feature_matching,\n",
    "    test_pca\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Recommand start with Notre Dame image.\n",
    "When you want to test out the other 2 images(Mount Rushmore,Episcopal Gaudi), you need to comment out the codes under Notre Dame and RERUN ALL cells below.\n",
    "''' \n",
    "\n",
    "# Notre Dame\n",
    "# image1 = load_image('../data/Notre Dame/921919841_a30df938f2_o.jpg')\n",
    "# image2 = load_image('../data/Notre Dame/4191453057_c86028ce1f_o.jpg')\n",
    "# eval_file = '../data/Notre Dame/921919841_a30df938f2_o_to_4191453057_c86028ce1f_o.pkl'\n",
    "\n",
    "# # Mount Rushmore -- this pair is relatively easy (still harder than Notre Dame, though)\n",
    "image1 = load_image('../data/Mount Rushmore/9021235130_7c2acd9554_o.jpg')\n",
    "image2 = load_image('../data/Mount Rushmore/9318872612_a255c874fb_o.jpg')\n",
    "eval_file = '../data/Mount Rushmore/9021235130_7c2acd9554_o_to_9318872612_a255c874fb_o.pkl'\n",
    "\n",
    "# # Episcopal Gaudi -- This pair is relatively difficult\n",
    "# image1 = load_image('../data/Episcopal Gaudi/4386465943_8cf9776378_o.jpg')\n",
    "# image2 = load_image('../data/Episcopal Gaudi/3743214471_1b5bbfda98_o.jpg')\n",
    "# eval_file = '../data/Episcopal Gaudi/4386465943_8cf9776378_o_to_3743214471_1b5bbfda98_o.pkl'\n",
    "\n",
    "                    \n",
    "scale_factor = 0.5\n",
    "image1 = cv2.resize(image1, (0, 0), fx=scale_factor, fy=scale_factor)\n",
    "image2 = cv2.resize(image2, (0, 0), fx=scale_factor, fy=scale_factor)\n",
    "image1_bw = cv2.cvtColor(image1, cv2.COLOR_RGB2GRAY)\n",
    "image2_bw = cv2.cvtColor(image2, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "n_pts = 1500 # width and height of each local feature, in pixels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find distinctive points in each image (Szeliski 4.1.1)\n",
    "### These are the results using the ground truth points\n",
    "\n",
    "#### Note: Image may take some time to appear \n",
    "\n",
    "If you face 'the STRING opcode argument must be quoted' error, simply reopen the 'pkl' file for image loacted in data folder  in VScode. Chage the CRLF to LF at the bottome right corner of VScode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x1, y1, x2, y2 = cheat_interest_points(eval_file, scale_factor)\n",
    "\n",
    "# Visualize the interest points\n",
    "c1 = show_interest_points(image1, x1, y1)\n",
    "c2 = show_interest_points(image2, x2, y2)\n",
    "plt.figure(); plt.imshow(c1)\n",
    "plt.figure(); plt.imshow(c2)\n",
    "print('{:d} corners in image 1, {:d} corners in image 2'.format(len(x1), len(x2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is where you implement and observe your results from `get_interest_points()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First some unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verify each step in the code, this will check if your implementation is correct or not.\n",
    "\n",
    "## Do not modify the constructor of any function (i.e. to take some custom arguments as input)\n",
    "\n",
    "print(\"Gaussian Kernel:\", verify(test_gaussian_kernel))\n",
    "print('Gradients test 1:', verify(test_get_gradients))\n",
    "print('Gradients test 2:', verify(test_get_gradients2))\n",
    "print('Second Moments:', verify(test_second_moment))\n",
    "print('Corner Response:', verify(test_corner_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now run it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1, R1, _= get_interest_points(image1_bw, n_pts)\n",
    "x2, y2, R2, _= get_interest_points(image2_bw, n_pts)\n",
    "c1 = show_interest_points(image1, x1, y1)\n",
    "c2 = show_interest_points(image2, x2, y2)\n",
    "plt.figure(); plt.imshow(c1)\n",
    "plt.figure(); plt.imshow(c2)\n",
    "print('{:d} corners in image 1, {:d} corners in image 2'.format(len(x1), len(x2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Interest Points:', verify(test_get_interest_points))\n",
    "print('Interest Points Single Corner:', verify(test_find_single_valid_corner))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create feature vectors at each interest point (Szeliski 4.1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is where you will code the functions in `student_sift.py`. Run the following cell to test your implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Magnitudes and Orientations:\", verify(test_get_magnitudes_and_orientations))\n",
    "print('Feature Vector', verify(test_get_feat_vec))\n",
    "print('All Feature Vectors', verify(test_get_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect features from our image pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_width = 16\n",
    "image1_features = get_features(image1_bw, x1, y1, feature_width)\n",
    "image2_features = get_features(image2_bw, x2, y2, feature_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match features (Szeliski 4.1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete `compute_feature_distances()` and `feature_matching()` in `student_feature_matching.py`. The following cell will test your implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature Distances:\", verify(test_compute_dists))\n",
    "print('Matches:', verify(test_feature_matching))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Match features for our image pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "matches, confidences = match_features(image1_features, image2_features)\n",
    "end = time.time()\n",
    "unoptimized = end - start\n",
    "print('{:d} matches from {:d} corners'.format(len(matches), len(x1)))\n",
    "print('Time Elapsed: {}'.format(unoptimized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "You might want to set 'num_pts_to_visualize' and 'num_pts_to_evaluate' to some constant (e.g. 100) once you start detecting hundreds of interest points, otherwise things might get too cluttered. You could also threshold based on confidence.  \n",
    "  \n",
    "There are two visualization functions below. **Note: For the report, use the visualization that shows correspondance lines (not circles)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_pts_to_visualize = len(matches)\n",
    "num_pts_to_visualize = 100\n",
    "c1 = show_correspondence_circles(image1, image2,\n",
    "                    x1[matches[:num_pts_to_visualize, 0]], y1[matches[:num_pts_to_visualize, 0]],\n",
    "                    x2[matches[:num_pts_to_visualize, 1]], y2[matches[:num_pts_to_visualize, 1]])\n",
    "plt.figure(); plt.imshow(c1)\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "plt.savefig('../results/vis_circles.png', dpi=1000)\n",
    "\n",
    "c2 = show_correspondence_lines(image1, image2,\n",
    "                    x1[matches[:num_pts_to_visualize, 0]], y1[matches[:num_pts_to_visualize, 0]],\n",
    "                    x2[matches[:num_pts_to_visualize, 1]], y2[matches[:num_pts_to_visualize, 1]])\n",
    "plt.figure(); plt.imshow(c2)\n",
    "plt.savefig('../results/vis_lines.png', dpi=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment out the function below if you are not testing on the Notre Dame, Episcopal Gaudi, and Mount Rushmore image pairs--this evaluation function will only work for those which have ground truth available.  \n",
    "  \n",
    "You can use `collect_ground_truth_corr.py` to build the ground truth for other image pairs if you want, but it's very tedious. It would be a great service to the class for future years, though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_pts_to_evaluate = len(matches)\n",
    "num_pts_to_evaluate = 100\n",
    "_, c = evaluate_correspondence(image1, image2, eval_file, scale_factor,\n",
    "                        x1[matches[:num_pts_to_evaluate, 0]], y1[matches[:num_pts_to_evaluate, 0]],\n",
    "                        x2[matches[:num_pts_to_evaluate, 1]], y2[matches[:num_pts_to_evaluate, 1]])\n",
    "plt.figure(); plt.imshow(c)\n",
    "plt.savefig('../results/eval.png', dpi=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bells and Whistles tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PCA: \", verify(test_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 24\n",
    "start = time.time()\n",
    "reduced_image1_features, reduced_image2_features = pca(image1_features, image2_features, n_components)\n",
    "matches, confidences = match_features(reduced_image1_features, reduced_image2_features)\n",
    "end = time.time()\n",
    "pca_optimized = end - start\n",
    "print('{:d} matches from {:d} corners'.format(len(matches), len(x1)))\n",
    "print('Time Elapsed (PCA): {}'.format(pca_optimized))\n",
    "print('Time Elapsed (no optimization): {}'.format(unoptimized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: For the report, use the visualization that shows correspondance lines (not circles)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_pts_to_visualize = len(matches)\n",
    "num_pts_to_visualize = 100\n",
    "c1 = show_correspondence_circles(image1, image2,\n",
    "                    x1[matches[:num_pts_to_visualize, 0]], y1[matches[:num_pts_to_visualize, 0]],\n",
    "                    x2[matches[:num_pts_to_visualize, 1]], y2[matches[:num_pts_to_visualize, 1]])\n",
    "plt.figure(); plt.imshow(c1)\n",
    "plt.savefig('../results/vis_circles_pca.png', dpi=1000)\n",
    "c2 = show_correspondence_lines(image1, image2,\n",
    "                    x1[matches[:num_pts_to_visualize, 0]], y1[matches[:num_pts_to_visualize, 0]],\n",
    "                    x2[matches[:num_pts_to_visualize, 1]], y2[matches[:num_pts_to_visualize, 1]])\n",
    "plt.figure(); plt.imshow(c2)\n",
    "plt.savefig('../results/vis_lines_pca.png', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_pts_to_evaluate = len(matches)\n",
    "num_pts_to_evaluate = 100\n",
    "_, c = evaluate_correspondence(image1, image2, eval_file, scale_factor,\n",
    "                        x1[matches[:num_pts_to_evaluate, 0]], y1[matches[:num_pts_to_evaluate, 0]],\n",
    "                        x2[matches[:num_pts_to_evaluate, 1]], y2[matches[:num_pts_to_evaluate, 1]])\n",
    "plt.figure(); plt.imshow(c)\n",
    "plt.savefig('../results/eval_pca.png', dpi=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accelerated Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "matches, confidences = accelerated_matching(image1_features, image2_features)\n",
    "end = time.time()\n",
    "accelerated = end - start\n",
    "print('{:d} matches from {:d} corners'.format(len(matches), len(x1)))\n",
    "print('Time Elapsed (Accelerated): {}'.format(accelerated))\n",
    "print('Time Elapsed (PCA): {}'.format(pca_optimized))\n",
    "print('Time Elapsed (no optimization): {}'.format(unoptimized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: For the report, use the visualization that shows correspondance lines (not circles)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_pts_to_visualize = len(matches)\n",
    "num_pts_to_visualize = 100\n",
    "c1 = show_correspondence_circles(image1, image2,\n",
    "                    x1[matches[:num_pts_to_visualize, 0]], y1[matches[:num_pts_to_visualize, 0]],\n",
    "                    x2[matches[:num_pts_to_visualize, 1]], y2[matches[:num_pts_to_visualize, 1]])\n",
    "plt.figure(); plt.imshow(c1)\n",
    "plt.savefig('../results/vis_circles_am.png', dpi=1000)\n",
    "c2 = show_correspondence_lines(image1, image2,\n",
    "                    x1[matches[:num_pts_to_visualize, 0]], y1[matches[:num_pts_to_visualize, 0]],\n",
    "                    x2[matches[:num_pts_to_visualize, 1]], y2[matches[:num_pts_to_visualize, 1]])\n",
    "plt.figure(); plt.imshow(c2)\n",
    "plt.savefig('../results/vis_lines_am.png', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_pts_to_evaluate = len(matches)\n",
    "num_pts_to_evaluate = 100\n",
    "_, c = evaluate_correspondence(image1, image2, eval_file, scale_factor,\n",
    "                        x1[matches[:num_pts_to_evaluate, 0]], y1[matches[:num_pts_to_evaluate, 0]],\n",
    "                        x2[matches[:num_pts_to_evaluate, 1]], y2[matches[:num_pts_to_evaluate, 1]])\n",
    "plt.figure(); plt.imshow(c)\n",
    "plt.savefig('../results/eval_am.png', dpi=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
